{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving demo for sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import sklearn.model_selection \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "Xtr_path = 'Xtr.csv'\n",
    "ytr_path = 'ytr.csv'\n",
    "Xts_path = 'Xts.csv'\n",
    "\n",
    "Xtr = np.loadtxt(Xtr_path, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_path, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_path, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "\n",
    "scaler = StandardScaler() # could also use RobustScaler() here!\n",
    "Xtr = scaler.fit_transform(Xtr) # compute standardization from training data and apply to training data\n",
    "Xts = scaler.fit_transform(Xts) # compute standardization from testing data and apply to testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual LASSO refit:\n",
      " intrcpt 0.000000\n",
      "       0 0.710419\n",
      "       1 -1.194056\n",
      "       2 1.003718\n",
      "       3 0.828824\n",
      "       4 -0.119656\n",
      "       5 2.336672\n",
      "       6 0.304381\n",
      "       7 -0.929152\n",
      "       8 0.008433\n",
      "       9 -0.044465\n",
      "      10 -0.139905\n",
      "      11 0.060662\n",
      "      12 0.074280\n",
      "      13 0.066365\n",
      "      14 -0.020887\n",
      "      15 -0.066928\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "\n",
    "import sklearn.model_selection \n",
    "\n",
    "# Manual approach using 2 for-loops\n",
    "\n",
    "# Create a k-fold cross validation object\n",
    "nfold = 10\n",
    "kf = sklearn.model_selection.KFold(n_splits=nfold,shuffle=True,random_state=2)\n",
    "\n",
    "# Create the LASSO model.  We use the `warm start` parameter so that the fit will start at the previous value.\n",
    "# This speeds up the fitting.\n",
    "lasso = Lasso(fit_intercept=False,warm_start=True)\n",
    "\n",
    "# Regularization values to test\n",
    "nalpha = 100\n",
    "alphas = np.logspace(-3,1,nalpha)\n",
    "\n",
    "# MSE for each alpha and fold value\n",
    "mse = np.zeros((nalpha,nfold))\n",
    "for ifold, ind in enumerate(kf.split(Xtr)):\n",
    "    \n",
    "    # Get the training data in the split\n",
    "    Itr,Its = ind\n",
    "    X_tr = Xtr[Itr,:]\n",
    "    y_tr = ytr[Itr]\n",
    "    \n",
    "    # Compute the lasso path for the split\n",
    "    for ia, a in enumerate(alphas):\n",
    "        \n",
    "        # Fit the model on the training data\n",
    "        lasso.alpha = a\n",
    "        lasso.fit(X_tr,y_tr)\n",
    "        \n",
    "        # Compute the prediction error on the test data\n",
    "        y_tr_pred = lasso.predict(X_tr)\n",
    "        mse[ia,ifold] = np.mean((y_tr_pred-y_tr)**2)\n",
    "\n",
    "# Compute the MSE mean over the folds and its standard error\n",
    "mse_cv = np.mean(mse,axis=1)\n",
    "mse_se = np.std(mse,axis=1,ddof=1) / np.sqrt(nfold)\n",
    "\n",
    "# Find the minimum MSE\n",
    "imin = np.argmin(mse_cv)\n",
    "alpha_min = alphas[imin]\n",
    "mse_cv_lasso = mse_cv[imin]\n",
    "\n",
    "# Manual approach to refitting LASSO on entire training data\n",
    "lasso.alpha = alpha_min\n",
    "lasso.fit(Xtr,ytr)\n",
    "print('Manual LASSO refit:')\n",
    "print(\" intrcpt %f\" % lasso.intercept_)\n",
    "for i, c in enumerate(lasso.coef_):\n",
    "    print(\"%8s %f\" % (i, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00843319, 0.02088663, 0.04446468, 0.0606617 , 0.06636467,\n",
       "       0.06692842, 0.07427952, 0.11965633, 0.13990481, 0.30438119,\n",
       "       0.71041853, 0.82882422, 0.92915234, 1.00371826, 1.19405587,\n",
       "       2.33667166])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort coefficient\n",
    "np.sort(abs(lasso.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select important features \n",
    "Xtr = Xtr[:,[0,1,2,3,4,5,6,7]]\n",
    "Xts = Xts[:,[0,1,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model\n",
    "\n",
    "svc = svm.SVC(probability=False, kernel=\"rbf\", C=47.5, gamma=1.05, verbose=1)\n",
    "#svc = svm.SVC(probability=False, kernel=\"rbf\", C=47.25, gamma=1.025, verbose=1) 91.760\n",
    "svc.fit(Xtr,ytr)\n",
    "\n",
    "acc = np.mean(svc.predict(Xtr)==ytr)\n",
    "print('training accuracy: ',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "np.savetxt(\"Xtr2.csv\", Xtr, delimiter=\",\")\n",
    "np.savetxt(\"Xts2.csv\", Xts, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model using the extension .pkl \n",
    "save_path = 'model.pkl'\n",
    "pickle.dump(svc, open(save_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy =  0.9945\r\n",
      "test label predictions saved in yts_hat.csv\r\n"
     ]
    }
   ],
   "source": [
    "# verify that the saved model works with the validation script\n",
    "Xts_path = 'Xts2.csv' # custom test features\n",
    "Xtr_path = 'Xtr2.csv' # custom training features\n",
    "!python {\"validation.py \" + save_path + \" --Xts_path \" + Xts_path + \" --Xtr_path \" + Xtr_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
